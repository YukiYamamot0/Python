# -*- coding: utf-8 -*-
"""
Created on Wed Jun 30 17:33:30 2021

@author: Yuki Yamamoto
"""

import numpy as np 
import matplotlib.pyplot as plt 
import pandas as pd 
import mglearn
import os
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import OneHotEncoder

X, y = mglearn.datasets.make_wave(n_samples=120)
line = np.linspace(-3, 3, 1000, endpoint=False).reshape(-1, 1)

reg = DecisionTreeRegressor(min_samples_leaf=3).fit(X, y)
plt.plot(line, reg.predict(line), label="decision tree")

reg = LinearRegression().fit(X, y)
plt.plot(line, reg.predict(line), label="linear regression")

plt.plot(X[:, 0], y, 'o', c='k')
plt.ylabel("Regression output")
plt.xlabel("Input feature")
plt.legend(loc="best")

#In[11]:
bins = np.linspace(-3, 3, 11)
#In[11]:
which_bin = np.digitize(X, bins=bins)

from sklearn.preprocessing import OneHotEncoder

# OneHotEncoderで変換する
encoder = OneHotEncoder(sparse=False)
# encoder.fitでwhich_binに現れる整数値のバリエーションを確認
encoder.fit(which_bin)
# transformでワンホットエンコーディングを行う
X_binned = encoder.transform(which_bin)
line_binned = encoder.transform(np.digitize(line, bins=bins))


#in[16]
X_combined  = np.hstack([X,X_binned])
print(X_combined.shape)

#in[17]
reg = LinearRegression().fit(X_combined, y)

line_combined = np.hstack([line, line_binned])
plt.plot(line, reg.predict(line_combined), label='linear regression combined')

for bin in bins:
    plt.plot([bin, bin],[-3,3],':',c='k')
plt.legend(loc="best")
plt.ylabel("Regression output")
plt.xlabel("Input Feature")
plt.plot(X[:,0],y,'o',c='k')

#in[18]
X_product = np.hstack([X_binned, X*X_binned])
print(X_product.shape)

#in[19]
reg = LinearRegression().fit(X_product, y)

line_product = np.hstack([line_binned, line * line_binned])
plt.plot(line, reg.predict(line_product),label='linear regression product')
for bin in bins:
    plt.plot([bin, bin],[-3,3],':',c='k')
plt.plot(X[:,0],y,'o',c='k')
plt.legend(loc="best")
plt.ylabel("Regression output")
plt.xlabel("Input Feature")

#in[20]
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree= 10, include_bias=False)
poly.fit(X)
X_poly = poly.transform(X)

#in[21]
print("X_poly.shape:{}".format(X_poly.shape))

#in[22]
print("Entries of X:\n{}".format(X[:5]))
print("Entries of X_poly:\n{}".format(X_poly[:5]))

#in[23]
print("Polynomial feature names:\n{}".format(poly.get_feature_names()))

#in[24]
reg = LinearRegression().fit(X_poly, y)

line_poly = poly.transform(line)
plt.plot(line, reg.predict(line_poly),label='polynomial linear regression')

#in[25]
from sklearn.svm import SVR

for gamma in[1, 10]:
    svr = SVR(gamma = gamma).fit(X, y)
    plt.plot(line,svr.predict(line),label='SVR gama={}'.format(gamma))

plt.plot(X[:,0],y,'o',c='k')
plt.legend(loc="best")
plt.ylabel("Regression output")
plt.xlabel("Input Feature")

#in[26]
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing  import MinMaxScaler

boston = load_boston()
X_train,X_test,y_train,y_test=train_test_split(
    boston.data, boston.target, random_state=0)
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#in[27]
poly = PolynomialFeatures(degree=2).fit(X_train_scaled)
X_train_poly=poly.transform(X_train_scaled)
X_test_poly=poly.transform(X_test_scaled)
print("X_train.shape:{}".format(X_train.shape))
print("X_train_poly.shape:{}".format(X_train_poly.shape))

#in[28]
print("Polynomial feature names:\n{}".format(poly.get_feature_names()))

#in[29]
from sklearn.linear_model import Ridge

ridge = Ridge().fit(X_train_scaled, y_train)
print("Score without interactions: {:.3f}".format(
    ridge.score(X_test_scaled, y_test)))
ridge = Ridge().fit(X_test_poly, y_test)
print("score with interactions: {:.3f}".format(
    ridge.score(X_test_poly,y_test)))

#in[30]
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100).fit(X_train_scaled, y_train)
print("Score without interactions:{:.3f}".format(
    rf.score(X_test_scaled,y_test)))
rf = RandomForestRegressor(n_estimators=100).fit(X_train_poly, y_train)
print("Score with interaction: {:.3f}".format(rf.score(X_test_poly,y_test)))
                                                             
